\section{Introduction}

We study the type-inference problem for a dependently
typed calculus with \emph{alpha-equality} of types.

\paragraph{Dependently typed calculus.} We use a unified
representation for different syntactic levels (except polymorphic
types) by following the pure type system representation of the
calculus of constructions ($\lambda C$).

This system is economic in that one set of rules covers all syntactic
level. However it also includes complexity when dealing with the
dependency of Pi types in type checking. Take an example:

\begin{lstlisting}
let f = \a. \b:a. b in \x. \y. f y x.
\end{lstlisting}

Here in the let body, \lst x cannot be of type \lst y because \lst y
does not exist when \lst x is introduced, so this program will be
rejected.

\paragraph{Let generalization.} Introducing let rule in dependently
typed system needs extra efforts. Take an example:

\begin{lstlisting}
let a = int in \x:a. x+1
\end{lstlisting}

It can pass the type check only if we know \lst{a} is just another
name of \lst{int} when infer \lst{x+1}. But in usual let rule, we will
only pass \lst{a:*} to the let body. It is not enough here. So we will
store the whole let binding \lst{a:*=int} in the context and use the
binding when needed.

And as tranditional Damas-Milner type inference, we will do
polymorphic generalization at let bindings. So expression:

\begin{lstlisting}
let id = \x. x in \x:(id nat). id 3
\end{lstlisting}

could pass the type check. This is the only way polymorphism would
appear in the type system. This means, the polymorphism is rank-one
and could only be generated by type system at let bingdings.

\paragraph{Higher-kinds} Since our type system uses a unified representation for different syntactic levels, $\star$ (the type of types) is also regarded as a value. Then we could easily achieve higher-order of $\star$, namely higher-kinds.

Consider the program:

\begin{lstlisting}
let tc = \f . f int in \x : tc Id . x
\end{lstlisting}

Our system is capable of infering this example, where \lst {tc} has type \lstinline{forall a:*. (* -> a) -> a}.

\paragraph{Explicit type-level computation.} $\lambda C$ supports beta
equality of types. Which means, the following two types are equal
under beta reduction:

\begin{lstlisting}
(\x:*. x) int
int
\end{lstlisting}

While the beta conversion rule brings a lot of convenience, an
unfortunate consequence is that it makes decidability of type
checking much harder. For type-inference purposes, we believe
this also creates difficulties. For example, if we consider
traditional unification, the unification algorithm would need
to be able to unify the two types above. However, higher-order
unification is undecidable.

In our type system, we use type-safe cast construct $\castdn$ (beta
reduction) and $\ercastup$ (beta expansion) to make type computation
explicit. Which means, type equality is based on $\alpha$-equality and
type \lst{(\\x:*. x) int} cannot be regarded as type \lst{int}.

$\castdn$ operator makes the resulting type be a beta reduction of the
original type of the term. So

\begin{lstlisting}
e1 : (\x:*. x) int
e2 = $\castdn$e1 : int
\end{lstlisting}

$\ercastup$ operator makes the resulting type be a beta expansion of
the original type of the term. But for a specific type, there are
unlimited types that can be reduced to the original type. So when
using $\ercastup$, we need to provide the type we want to cast to:

\begin{lstlisting}
$\ercastup$[(\x:*. x) int] e2 : (\x:*. x) int
$\ercastup$[(\x:int. int) 2] e2 : (\x:int. int) 2
\end{lstlisting}

Cast construct allows only one-step reduction or expansion. So we have

\begin{lstlisting}
e1 : (\x:*. \y:int. x) int 2
$\castdn$e1 : (\y:int. int) 2
$\castdn \castdn$e1 : int
\end{lstlisting}

\paragraph{Difficulties}
One particular difficulty that we encountered was the influence of the dependency of Pi type on throwing away trailing context and destructing of function types.

Due to dependency, the return type of a dependently typed function could refer to the outer bound varibles. For example expression \lst{\\x:*.\\y:x.y} of type $\bpi x \star {\bpi y x x}$. So while infering a lambda case, it changes the order of the existential variable that represents the return type, and the bound variable in the context, which also results to a different way dealing with trailing context. And also, while unifying an existential variable with the above type, we cannot simply destruct the existential variable into Pi type form like $\genA = \bpi x {\genA_1} {\genA_2}$, because $\genA_2$ could mention $x$.

\paragraph{Limitations so far}
One limitation is that currently the system does not support
higher-rank polymorphism. We attempted to extend the system
with higher-ranked polymorphism, but this seemed quite complex.
It remains to be seen whether the complexity is fundamental, or
whether we missed something. It may be the case that we need to
introduce some restrictions (for example predicativity).


\paragraph{Contributions.} In summary, the contributions of this work are:
\begin{itemize}
\item We give a set of algorithmic bidirectional typing rules for dependently typed calculus, where a unified representation is used for different syntactic levels with higher kind.
\item By using ordered context, dealing with let bindings is quite simple. And we preserve the Damas-Milner way of let polymorphism.
\item Explicit type casts allows type unification to be based on alpha equality and the decidability of type-level computation is achieved.
\end{itemize}
