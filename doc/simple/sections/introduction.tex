\section{Introduction}

\paragraph{Dependently typed calculus.} We uses a unified representation for different syntactic levels (except polymorphism type) by following the pure type system representation of the calculus of constructions ($\lambda C$).

This system is economic in that one set of rules covers all syntactic level, but it also includes complexity while dealing with the dependency of Pi type in type checking. Take an example:

\begin{lstlisting}
let f = \a. \b:a. b in \x. \y. f y x.
\end{lstlisting}

Here in the let body, \lst x cannot be of type \lst y because \lst y does not exist when \lst x is introduced, so this program will be rejected.

\paragraph{Explicit type-level computation.} $\lambda C$ supports beta equality of types. Which means, the following two types are equal under beta reduction:

\begin{lstlisting}
(\x:*. x) int
int
\end{lstlisting}

While the beta conversion rule brings a lot of convenience, an unfortunate consequence is that it couples decidability of type checking with strong noralization of calculus. Therefore adding general recursion to $\lambda C$ becomes difficult, since strong normalization is lost. Futhermore, any diverging computation on type level will make type checker get stuck.

In our type system, we use type-safe cast construct $\castdn$ (beta reduction) and $\ercastup$ (beta expansion) to make type computation explicit. Which means, type equality is based on $\alpha$-equality and type \lst{(\\x:*. x) int} cannot be regarded as type \lst{int}.

$\castdn$ operator makes the resulting type be a beta reduction of the original type of the term. So

\begin{lstlisting}
e1 : (\x:*. x) int
e2 = $\castdn$e1 : int
\end{lstlisting}

$\ercastup$ operator makes the resulting type be a beta expansion of the original type of the term. But for a specific type, there are unlimited types that can be reduced to the original type. So when using $\ercastup$, we need to provide the type we want to cast to:

\begin{lstlisting}
$\ercastup$[(\x:*. x) int] e2 : (\x:*. x) int
$\ercastup$[(\x:int. int) 2] e2 : (\x:int. int) 2
\end{lstlisting}

Cast construct allows only one-step reduction or expansion. So we have

\begin{lstlisting}
e1 : (\x:*. \y:int. x) int 2
$\castdn$e1 : (\y:int. int) 2
$\castdn \castdn$e1 : int
\end{lstlisting}

\paragraph{Let generalization.} Introducing let rule in dependently typed system needs extra efforts. Take an example:

\begin{lstlisting}
let a = int in \x:a. x+1
\end{lstlisting}

It can pass the type check only if we know \lst{a} is just another name of \lst{int} when infer \lst{x+1}. But in usual let rule, we will only pass \lst{a:*} to the let body. It is not enough here. So we will store the whole let binding \lst{a:*=nat} in the context and use the binding when needed.

And as tranditional Damas-Milner type inference, we will do polymorphic generalization at let bindings. So expression:

\begin{lstlisting}
let id = \x. x in \x:(id nat). id 3
\end{lstlisting}

could pass the type check. This is the only way polymorphism would appear in the type system. This means, the polymorphism is rank-one and could only be generated by type system at let bingdings.

\paragraph{Contributions.} In summary, the contributions of this work are:
\begin{itemize}
\item We give a set of algorithmic bidirectional typing rules for dependently typed calculus, where a unified representation is used for different syntactic levels with higher kind.
\item By using ordered context, dealing with let bindings is quite simple. And we preserve the Damas-Milner way of let polymorphism.
\item Explicit type casts allows type unification to be based on alpha equality and the decidability of type-level computation is achieved.
\end{itemize}
